{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond Merrity zadatak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "from deep_translator import GoogleTranslator\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Display full DataFrames\n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Read data (promijeniti putanju do datoteke)\n",
    "train = pd.read_excel('D:/Documents/Posao/Prijave/Spona_code/Zadatak/train.xlsx')\n",
    "test = pd.read_excel('D:/Documents/Posao/Prijave/Spona_code/Zadatak/test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment categories\n",
    "\n",
    "minus_three = {'stalno',\n",
    "'previše',\n",
    "'nema',\n",
    "'nema ravnoteže',\n",
    "'neravnoteže',\n",
    "'na strani poslovnog',\n",
    "'nefleksibilnost'\n",
    "}\n",
    "\n",
    "minus_two = {'neravnoteža',\n",
    "'loše',\n",
    "'narušen' \n",
    "}\n",
    "\n",
    "minus_one = {'manje privatnog života',\n",
    "'nije najbolje',\n",
    "'covid loše',\n",
    "'manjak home-office',\n",
    "'izazove',\n",
    "'dosta malo privatnog'\n",
    "}\n",
    "\n",
    "zero = {'kako kad', 'nije kod svih isto'}\n",
    "\n",
    "one = {'može bolje',\n",
    "'raditi sam na tome',\n",
    "'kompromisi',\n",
    "'ovisno',\n",
    "'ovisi'\n",
    "}\n",
    "\n",
    "two = {'ovisi o meni',\n",
    "'podnošljivo',\n",
    "'povremeno optimalno',\n",
    "'balansirano'\n",
    "}\n",
    "\n",
    "three = {'pozitivno',\n",
    "'zadovoljna',\n",
    "'zadovoljan',\n",
    "'ok',\n",
    "'fair',\n",
    "'balans',\n",
    "'dobro',\n",
    "'postoji balans',\n",
    "'pozitivno iskustvo', \n",
    "'dobro',\n",
    "'fleksibilnost',\n",
    "'dobar',\n",
    "'ok je',\n",
    "}\n",
    "\n",
    "four = {'odlično',\n",
    "'ravnoteža u potpunosti',\n",
    "'vrlo zadovoljna',\n",
    "'uravnoteženo',\n",
    "'dobra ravnoteža',\n",
    "'uravnoteženo',\n",
    "'fleksibilno', \n",
    "'otvorenog uma', \n",
    "'prihvatljivo',\n",
    "'balansirano',\n",
    "'vrlo dobro',\n",
    "}\n",
    "\n",
    "five = {'sklad', 'super'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine sentiment on predefined categories\n",
    "\n",
    "def get_sentiment(sentence):\n",
    "  sent=0\n",
    "  words = [word.lower() for word in nltk.word_tokenize(sentence)]\n",
    "  for word in words:\n",
    "    if word in minus_three:\n",
    "      sent -= 3\n",
    "    elif word in minus_two:\n",
    "      sent -= 2\n",
    "    elif word in minus_one:\n",
    "      sent -= 1\n",
    "    elif word in one:\n",
    "      sent += 1\n",
    "    elif word in two:\n",
    "      sent += 2\n",
    "    elif word in three:\n",
    "      sent += 3\n",
    "    elif word in four:\n",
    "      sent += 4\n",
    "    elif word in five:\n",
    "      sent += 5\n",
    "    if sent > 5:\n",
    "        sent = 5\n",
    "    if sent < -5:\n",
    "        sent = -5\n",
    "  return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['my_sentiment'] = test['review'].apply(get_sentiment)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nedostaje puno riječi, pa je puno rezultata 0\n",
    "- za riječi iz riječnika relativno dobri rezultati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Translate to english\n",
    "translator = GoogleTranslator(source='hr', target='en')\n",
    "\n",
    "for i in range(len(train)):\n",
    "    train.loc[i, 'review_en'] = translator.translate(train.loc[i, 'review'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean, remove punctuation, digits...\n",
    "def clean(text):\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    return text\n",
    "\n",
    "train['clean_reviews'] = train['review_en'].apply(clean)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove stopwords and tag parts of speech\n",
    "\n",
    "sw = nltk.corpus.stopwords.words('english')\n",
    "not_sw = {'not', 'no', 'can', 'do', 'very'} \n",
    "new_sw = set([word for word in sw if word not in not_sw])\n",
    "\n",
    "\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in new_sw:\n",
    "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "train['pos'] = train['clean_reviews'].apply(token_stop_pos)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create lemmas\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "train['lemma'] = train['pos'].apply(lemmatize)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob polarity\n",
    "def getPolarity(review):\n",
    "    return TextBlob(review).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['polarity'] = train['lemma'].apply(getPolarity) \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rescale polarity to get in range of sentiment (-5 - 5 instead of -1 - 1)\n",
    "\n",
    "def rescale(col):\n",
    "    if col >= -1 and col < -0.8:\n",
    "        col = -5\n",
    "    elif col >= -0.8 and col <= -0.6:\n",
    "        col = -4\n",
    "    elif col >= -0.6 and  col <= -0.4:\n",
    "        col = -3\n",
    "    elif col >= -0.4 and  col <= -0.2:\n",
    "        col = -2\n",
    "    elif col >= -0.2 and  col < 0:\n",
    "        col = -1\n",
    "    elif col == 0:\n",
    "        col = 0\n",
    "    elif col >= 0 and  col <= 0.2:\n",
    "        col = 1\n",
    "    elif col >= 0.2 and  col <= 0.4:\n",
    "        col = 2\n",
    "    elif col >= 0.4 and  col <= 0.6:\n",
    "        col = 3\n",
    "    elif col >= 0.6 and  col < 0.8:\n",
    "        col = 4\n",
    "    else:\n",
    "        col = 5\n",
    "    return col\n",
    "\n",
    "train['blob_sentiment'] = train['polarity'].apply(rescale)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate, clean... the test set in the same way\n",
    "\n",
    "for i in range(len(test)):\n",
    "    test.loc[i, 'review_en'] = translator.translate(test.loc[i, 'review']) \n",
    "\n",
    "test['clean_reviews'] = test['review_en'].apply(clean)\n",
    "\n",
    "test['pos'] = test['clean_reviews'].apply(token_stop_pos)\n",
    "\n",
    "test['lemma'] = test['pos'].apply(lemmatize)\n",
    "\n",
    "test['polarity'] = test['lemma'].apply(getPolarity)\n",
    "test['blob_sentiment'] = test['polarity'].apply(rescale)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- također puno nula, kontekst se ne uzima u obzir "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vader analyzer, add new relevant words and weights\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "new_words = {'overtime': -3.0, 'disturbed': -2.0,'compromise': 1.0, 'compromises': 1.0,\n",
    "             'imbalance': -2.0,'no balance': -3.0, 'established': 4.0, 'depends': 0.0,\n",
    "             'balanced': 3.0, 'harmony': 5.0, 'tolerably': 2.0, 'tolerable': 2.0,\n",
    "             'flexibility': 3.0, 'flexible': 3.0, 'open-minded': 4.0, 'inflexibility': -3.0,\n",
    "             'inflexible': -3.0}\n",
    "\n",
    "analyzer.lexicon.update(new_words)\n",
    " \n",
    "def vadersentimentanalysis(review):\n",
    "    vs = analyzer.polarity_scores(review)\n",
    "    return vs['compound']\n",
    "\n",
    "train['vader_polarity'] = train['review_en'].apply(vadersentimentanalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rescale for easier comparisson with sentiment\n",
    "train['vader_sentiment'] = train['vader_polarity'].apply(rescale)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply VADER to test set and rescale\n",
    "test['vader_polarity'] = test['review_en'].apply(vadersentimentanalysis)\n",
    "test['vader_sentiment'] = test['vader_polarity'].apply(rescale)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bolje od textblob-a pošto se mogu dodati custom riječi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer, Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vectorizers\n",
    "cvect = CountVectorizer(ngram_range=(1,1), max_features=100)\n",
    "tfvect = TfidfVectorizer(ngram_range=(1,1), max_features=100)\n",
    "\n",
    "csparse = cvect.fit_transform(train.review_en)\n",
    "tfsparse = tfvect.fit_transform(train.review_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Transform sparse matrix to dataframe\n",
    "train_df = pd.DataFrame(csparse.toarray(), columns=cvect.get_feature_names())\n",
    "train_df['sentiment'] = train.sentiment\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models and make predictions\n",
    "\n",
    "bayes = MultinomialNB()\n",
    "svc = LinearSVC()\n",
    "\n",
    "X = train_df.drop('sentiment', axis=1)\n",
    "y = train_df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "bayes.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred_b = bayes.predict(X_test)\n",
    "print(y_pred_b)\n",
    "\n",
    "y_pred_s = svc.predict(X_test)\n",
    "print(y_pred_s)\n",
    "\n",
    "print(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(accuracy_score(y_test, y_pred_b))\n",
    "print(accuracy_score(y_test, y_pred_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer, Supervised Learning test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize, transform to dataframe, predict\n",
    "csparse_test = cvect.fit_transform(test.review_en)\n",
    "test_df = pd.DataFrame(csparse_test.toarray(), columns=cvect.get_feature_names())\n",
    "test_y_pred = bayes.predict(test_df)\n",
    "test['bayes_sentiment'] = test_y_pred\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vrlo nizak accuracy, bilo bi bolje s većim setom za treniranje, a i onda bi se isplatilo namještati detalje modela i preprocessing-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usporedba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pred = train[['review', 'review_en', 'sentiment', 'blob_sentiment', 'vader_sentiment']]\n",
    "train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_range = [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = plt.subplot(1,3,1)\n",
    "sns.countplot(data=train, x='sentiment', order=sentiment_range)\n",
    "ax2 = plt.subplot(1,3,2, sharey=ax1)\n",
    "sns.countplot(data=train, x='blob_sentiment', order=sentiment_range)\n",
    "ax3 = plt.subplot(1,3,3, sharey=ax1)\n",
    "sns.countplot(data=train, x='vader_sentiment', order=sentiment_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Blob Accuracy:', accuracy_score(train.sentiment, train.blob_sentiment))\n",
    "print('VADER Accuracy', accuracy_score(train.sentiment, train.vader_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test[['review', 'review_en', 'my_sentiment', 'blob_sentiment', 'vader_sentiment', 'bayes_sentiment']]\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = plt.subplot(1,4,1)\n",
    "sns.countplot(data=test, x='my_sentiment', order=sentiment_range)\n",
    "ax2 = plt.subplot(1,4,2, sharey=ax1)\n",
    "sns.countplot(data=test, x='blob_sentiment', order=sentiment_range)\n",
    "ax3 = plt.subplot(1,4,3, sharey=ax1)\n",
    "sns.countplot(data=test, x='vader_sentiment', order=sentiment_range)\n",
    "ax4 = plt.subplot(1,4,4, sharey=ax1)\n",
    "sns.countplot(data=test, x='bayes_sentiment', order=sentiment_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_pred.to_excel('D:/Documents/Posao/Prijave/Spona_code/Zadatak/train_pred.xlsx')\n",
    "#test_pred.to_excel('D:/Documents/Posao/Prijave/Spona_code/Zadatak/test_pred.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zaključak\n",
    "- Određivanje sentimenta samo preko ručno definiranih kategorija riječi bi bilo bolje s više definiranih riječi ali vjerojatno bi bilo lakše koristiti preddefinirane (TextBlob, VADER...) iako u tom slučaju utječe i kvaliteta prijevoda\n",
    "- TextBlob nizak accuracy jer ne uzima u obzir work-life balance kontekst\n",
    "- Za supervised learning premalo uzoraka \n",
    "- Iako VADER daje najbolje rezultate jer je moguće dodati vlastite riječi i weights još uvijek je accuracy samo 30%\n",
    "    - bilo bi bolje s više uzoraka i više dodanih riječi s preciznije određenim weights-ima\n",
    "- čišćenje teksta (tokenizacija, lematizacija...) ili nije imalo utjecaja na rezultata ili su čak bili lošiji\n",
    "- isprobati preprocessing s paketima za hrvatski jezik i fuzzy matching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
